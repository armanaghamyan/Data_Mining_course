grid.arrange(b1,b2,b3,nrow=1)
grid.arrange(b1,b2,b3,nrow=2)
grid.arrange(b1,b2,b3,nrow=3)
grid.arrange(b1,b2,b3,nrow=4)
grid.arrange(b1,b2,b3,nrow=1)
set.seed(1)
b2<-ggplot(data = Wells, aes(y =distance, x = switch,color = switch))+
geom_boxplot()+
scale_x_discrete(labels= levels(Wells$switch) )+
stat_summary(fun.y = "mean",geom = 'point',col='red', shape=17, size=3)+
labs(title ="Distance by Switch " ,color =  "Switch",y='Distance',x="Switch")+
theme(plot.title = element_text(hjust = 1))
grid.arrange(b1,b2,b3,nrow=1)
b3<-ggplot(data = Wells, aes(y =education, x = switch,color = switch))+
geom_boxplot()+
scale_x_discrete(labels= levels(Wells$switch) )+
stat_summary(fun.y = "mean",geom = 'point',col='red', shape=17, size=3)+
labs(title ="Education by Switch " ,color =  "Switch",y='Education',x="Switch")+
theme(plot.title = element_text(hjust = 1))
b1<-ggplot(data = Wells, aes(y =arsenic, x = switch,color = switch))+
geom_boxplot()+
scale_x_discrete(labels= levels(Wells$switch) )+
stat_summary(fun.y = "mean",geom = 'point',col='red', shape=17, size=3)+
labs(title ="Arsenic by Switch " ,color =  "Switch",y='Arsenic',x="Switch")+
theme(plot.title = element_text(hjust = 1))
grid.arrange(b1,b2,b3,nrow=1)
index<-createDataPartition(Wells$switch,p=0.75,list = F)
Train<-Wells[index,]
Test<-Wells[-index,]
library(caret)
library(ROCR)
library(e1071)
model<-naiveBayes(switch~.,data=Train)
model<-naiveBayes(switch~.,data=Train,laplace = 1)
names(model)
model$apriori
model$tables
head(Wells)
d<-density(Wells$arsenic)
d
plot(d)
d1<-density(Wells$arsenic)
plot(d1)
d2<-sm.density.compare(switch, association, xlab="Miles Per Gallon")
library(sm)
install.packages("sm")
library(sm)
d2<-sm.density.compare(switch, association, xlab="Miles Per Gallon")
d2<-sm.density.compare(arsenic, association, xlab="Miles Per Gallon")
d1<-density(Wells$arsenic)
plot(d1)
d2<-sm.density.compare(Wells$arsenic, association, xlab="Miles Per Gallon")
d2<-sm.density.compare(Wells$arsenic, Wells$association, xlab="Miles Per Gallon")
title(main="MPG Distribution by Car Cylinders")
d2<-sm.density.compare(Wells$arsenic, Wells$association, xlab="Miles Per Gallon")
d2<-sm.density.compare(Wells$arsenic,Wells$switch, xlab="Miles Per Gallon")
d2<-sm.density.compare(Wells$distance,Wells$switch, xlab="Miles Per Gallon")
d2<-sm.density.compare(Wells$distance,Wells$arsenic,Wells$switch, xlab="Miles Per Gallon")
d2<-sm.density.compare(Wells$distance,Wells$switch, xlab="Miles Per Gallon")
hist(Wells$switch,Wells$association)
gplot(Wells, aes(x =arsenic)) +
geom_density() +
facet_wrap(~Species)
ggplot(Wells, aes(x =arsenic)) +
geom_density() +
facet_wrap(~Species)
ggplot(Wells, aes(x =arsenic)) +
geom_density() +
facet_wrap(~switch)
d2<-ggplot(Wells, aes(x =distance)) +
geom_density() +
facet_wrap(~switch)
d2
d3<-ggplot(Wells, aes(x =eductaion)) +
geom_density() +
facet_wrap(~switch)
d3
d3<-ggplot(Wells, aes(x =education)) +
geom_density() +
facet_wrap(~switch)
d3
grid.arrange(d1,d2,d3,nrow=1)
grid.arrange(d1,d2,d3,nrow=2)
grid.arrange(d1,d2,d3,nrow=3)
d3<-ggplot(Wells, aes(x =education)) +
geom_density() +
facet_wrap(~switch)
d3
d1
d1<-ggplot(Wells, aes(x =arsenic)) +
geom_density() +
facet_wrap(~switch)
d1
d2<-ggplot(Wells, aes(x =distance)) +
geom_density() +
facet_wrap(~switch)
d2
d3<-ggplot(Wells, aes(x =education)) +
geom_density() +
facet_wrap(~switch)
d3
library(sm)
d1<-ggplot(Wells, aes(x =arsenic)) +
geom_density() +
facet_wrap(~switch)
d1
d2<-ggplot(Wells, aes(x =distance)) +
geom_density() +
facet_wrap(~switch)
d2
d3<-ggplot(Wells, aes(x =education)) +
geom_density() +
facet_wrap(~switch)
d3
model$tables
model$tables$arsenic
model$tables
model$apriori
Prob_Yes<-model$apriori[2]/sum(model$apriori)
Prob_Yes
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
Prob_Yes
Prob_No
Prob_No<-1-Prob_Yes
Prob_No
Prob_Yes
Prob_No<-1-Prob_Yes
Prob_No
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
model$tables
mean(1.415254,1.841128)
model$tables$arsenic
summary(model$tables$arsenic)
summary(model$arsenic)
summary(Train$arsenic)
mean(1.415254,1.841128)
mean(1.415254+1.841128)
mean(1.415254,1.841128)
median(1.415254,1.841128)
mean(1.415254,1.841128)
(1.415254+1.841128)/2
model$tables$arsenic
model$tables
pnorm(2.5,1.415254,0.9554892)
Pred_no<-pnorm(2.5,1.415254,0.9554892)
model$tables
Pred_yes<-pnorm(2.5,1.841128,1.1880507)
Pred_no
Pred_yes
set.seed(1)
index<-createDataPartition(Wells$switch,p=0.75,list = F)
Train<-Wells[index,]
Test<-Wells[-index,]
model<-naiveBayes(switch~.,data=Train,laplace = 1)
names(model)
model$apriori
Prob_Yes<-model$apriori[2]/sum(model$apriori)
Prob_Yes
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
model$tables
Pred_no<-pnorm(2.5,1.415254,0.9554892)
Pred_no
Pred_yes<-pnorm(2.5,1.841128,1.1880507)
Pred_yes
max(Pred_no,Pred_yes)
set.seed(1)
index<-createDataPartition(Wells$switch,p=0.75,list = F)
Train<-Wells[index,]
Test<-Wells[-index,]
model<-naiveBayes(switch~.,data=Train,laplace = 1)
names(model)
model$apriori
Prob_Yes<-model$apriori[2]/sum(model$apriori)
Prob_Yes
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
model$tables
Pred_no<-pnorm(2.5,1.415254,0.9554892)
Pred_no
Pred_yes<-pnorm(2.5,1.841128,1.1880507)
Pred_yes
max(Pred_no,Pred_yes)
model$apriori
Prob_Yes
set.seed(1)
index<-createDataPartition(Wells$switch,p=0.75,list = F)
Train<-Wells[index,]
Test<-Wells[-index,]
model<-naiveBayes(switch~.,data=Train,laplace = 1)
names(model)
model$apriori
Prob_Yes<-model$apriori[2]/sum(model$apriori)
Prob_Yes
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
model$tables
Pred_no<-pnorm(2.5,1.415254,0.9554892)
Pred_no
Pred_yes<-pnorm(2.5,1.841128,1.1880507)
Pred_yes
max(Pred_no,Pred_yes)
set.seed(1)
index<-createDataPartition(Wells$switch,p=0.75,list = F)
Train<-Wells[index,]
Test<-Wells[-index,]
model<-naiveBayes(switch~.,data=Train,laplace = 1)
names(model)
model$apriori
Prob_Yes<-model$apriori[2]/sum(model$apriori)
Prob_Yes
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
model$tables
Pred_no<-pnorm(2.5,1.415254,0.9554892)
Pred_no
Pred_yes<-pnorm(2.5,1.841128,1.1880507)
Pred_yes
max(Pred_no,Pred_yes)
Pred_no
Prob_Yes
Prob_No
pred_test<-predict(model,newdata = Test)
confusionMatrix(pred_test,Test$switch,positive = "yes")
confusionMatrix(pred_test,Test$switch,positive = "no")
confusionMatrix(pred_test,Test$switch,positive = "yes")
confusionMatrix(pred_test,Test$switch,positive = "no")
confusionMatrix(pred_test,Test$switch,positive = "yes")
pred_test_prob<-predict(model,newdata = Test,type = "raw")
head(pred_test_prob)
P_Test<-prediction(pred_test_prob,Test$switch)
pred_test_prob<-predict(model,newdata = Test,type = "raw")
head(pred_test_prob)
P_Test<-prediction(pred_test_prob,Test$switch)
P_Test<-prediction(pred_test_prob[,2],Test$switch)
perf<-performance(P_Test,"prec","rec")
plot(perf,colorize=T)
P_Test<-prediction(pred_test_prob[,2],Test$switch)
perf<-performance(P_Test,"tpr","fpr")
plot(perf,colorize=T)
plot(perf,colorize=G)
plot(perf,colorize=T)
performance(P_Test,"auc")@y.values
index<-createDataPartition(Wells$switch,p=0.8,list = F)
Train<-Wells[index,]
Test<-Wells[-index,]
model<-naiveBayes(switch~.,data=Train,laplace = 1)
names(model)
model$apriori
Prob_Yes<-model$apriori[2]/sum(model$apriori)
Prob_Yes
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
model$tables
Pred_no<-pnorm(2.5,1.415254,0.9554892)
Pred_no
Pred_yes<-pnorm(2.5,1.841128,1.1880507)
Pred_yes
max(Pred_no,Pred_yes)
pred_test<-predict(model,newdata = Test)
confusionMatrix(pred_test,Test$switch,positive = "yes")
pred_test_prob<-predict(model,newdata = Test,type = "raw")
head(pred_test_prob)
P_Test<-prediction(pred_test_prob[,2],Test$switch)
perf<-performance(P_Test,"tpr","fpr")
plot(perf,colorize=T)
performance(P_Test,"auc")@y.values
index<-createDataPartition(Wells$switch,p=0.75,list = F)
Train<-Wells[index,]
#B
set.seed(1)
index<-createDataPartition(Wells$switch,p=0.75,list = F)
Train<-Wells[index,]
Test<-Wells[-index,]
model<-naiveBayes(switch~.,data=Train,laplace = 1)
names(model)
model$apriori
Prob_Yes<-model$apriori[2]/sum(model$apriori)
Prob_Yes
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
model$tables
Pred_no<-pnorm(2.5,1.415254,0.9554892)
Pred_no
Pred_yes<-pnorm(2.5,1.841128,1.1880507)
Pred_yes
max(Pred_no,Pred_yes)
pred_test<-predict(model,newdata = Test)
confusionMatrix(pred_test,Test$switch,positive = "yes")
pred_test_prob<-predict(model,newdata = Test,type = "raw")
head(pred_test_prob)
P_Test<-prediction(pred_test_prob[,2],Test$switch)
perf<-performance(P_Test,"tpr","fpr")
plot(perf,colorize=T)
performance(P_Test,"auc")@y.values
index<-createDataPartition(Wells$switch,p=0.8,list = F)
Train<-Wells[index,]
Test<-Wells[-index,]
model<-naiveBayes(switch~.,data=Train,laplace = 1)
names(model)
model$apriori
Prob_Yes<-model$apriori[2]/sum(model$apriori)
Prob_Yes
Prob_No<-model$apriori[1]/sum(model$apriori)
Prob_No
model$tables
Pred_no<-pnorm(2.5,1.421801,0.9695603)
Pred_no
model$tables
Pred_yes<-pnorm(2.5,1.823612,1.1798932)
Pred_yes
max(Pred_no,Pred_yes)
Pred_no
Pred_yes<-pnorm(2.5,1.823612,1.1798932)
Pred_yes
max(Pred_no,Pred_yes)
pred_test<-predict(model,newdata = Test)
confusionMatrix(pred_test,Test$switch,positive = "yes")
pred_test_prob<-predict(model,newdata = Test,type = "raw")
head(pred_test_prob)
P_Test<-prediction(pred_test_prob[,2],Test$switch)
perf<-performance(P_Test,"tpr","fpr")
plot(perf,colorize=T)
performance(P_Test,"auc")@y.values
confusionMatrix(pred_test,Test$switch,positive = "yes")
library(carData)
library(gridExtra)
# A)
data("Wells")
head(Wells)
library(ggplot2)
b1<-ggplot(data = Wells, aes(y =arsenic, x = switch,color = switch))+
geom_boxplot()+
scale_x_discrete(labels= levels(Wells$switch) )+
stat_summary(fun.y = "mean",geom = 'point',col='red', shape=17, size=3)+
labs(title ="Arsenic by Switch " ,color =  "Switch",y='Arsenic',x="Switch")+
theme(plot.title = element_text(hjust = 1))
b2<-ggplot(data = Wells, aes(y =distance, x = switch,color = switch))+
geom_boxplot()+
scale_x_discrete(labels= levels(Wells$switch) )+
stat_summary(fun.y = "mean",geom = 'point',col='red', shape=17, size=3)+
labs(title ="Distance by Switch " ,color =  "Switch",y='Distance',x="Switch")+
theme(plot.title = element_text(hjust = 1))
b3<-ggplot(data = Wells, aes(y =education, x = switch,color = switch))+
geom_boxplot()+
scale_x_discrete(labels= levels(Wells$switch) )+
stat_summary(fun.y = "mean",geom = 'point',col='red', shape=17, size=3)+
labs(title ="Education by Switch " ,color =  "Switch",y='Education',x="Switch")+
theme(plot.title = element_text(hjust = 1))
grid.arrange(b1,b2,b3,nrow=1)
library(caret)
library(ROCR)
library(e1071)
Income=c(125,100,70,120,150,60,220,85,75,90,180,200,250,50)
Howner=c("Yes","No","No","Yes","No","No","Yes","No","No","No","Yes","Yes","Yes","No")
Default=c("No","No","No","No","Yes","No","No","Yes","No","Yes","Yes","No","No","Yes")
Mstatus=c("Single","Married","Single","Married","Divorced","Married","Divorced","Single","Married","Single","Divorced","Divorced","Married","Married")
income_no=c(60,70,75,100,120,125,200,220,250)
mean(income_no)
sd(income_no)
income_yes=c(50,85,90,150,180)
mean(income_yes)
sd(income_yes)
P_income_no=pnorm(158,135.556,70.42036)
P_income_yes=pnorm(158,111,52.72571)
P_income_yes
P_income_no
addmargins(table(Howner,Default))
addmargins(table(Mstatus,Default))
P_how_yes<-1/5
P_how_no<-4/9
p_mst_single_yes<-2/5
p_mst_single_no<-2/9
p_mst_married_yes<-1/5
p_mst_married_no<-5/9
p_mst_divorced_yes<-2/5
p_mst_divorced_no<-2/9
P_income_yes
P_income_no
table(Default)
P_default_yes<-5/14
P_default_no<-9/14
P_h_yes=prod(P_how_yes,p_mst_single_yes,P_income_yes,P_default_yes)
P_h_yes
P_h_yes
P_income_yes
P_income_no
P_h_no=prod(P_how_no,p_mst_single_no,P_income_no,P_default_no)
P_h_yes
P_h_no
table(Default)
addmargins(table(Howner,Default))
addmargins(table(Howner,Default))
addmargins(table(Howner,Default))
addmargins(table(Mstatus,Default))
P_default_yes<-5/14
P_default_no<-9/14
P_how_yes<-1/5
P_how_no<-5/9
p_mst_single_yes<-2/5
p_mst_single_no<-2/9
p_mst_married_yes<-1/5
p_mst_married_no<-5/9
p_mst_divorced_yes<-2/5
p_mst_divorced_no<-2/9
P_h_yes=prod(P_how_yes,p_mst_single_yes,P_income_yes,P_default_yes)
P_h_yes
P_h_no=prod(P_how_no,p_mst_single_no,P_income_no,P_default_no)
P_h_no
max(P_h_no,P_h_yes)
library(caret)
library(ROCR)
library(e1071)
Income=c(125,100,70,120,150,60,220,85,75,90,180,200,250,50)
Howner=c("Yes","No","No","Yes","No","No","Yes","No","No","No","Yes","Yes","Yes","No")
Default=c("No","No","No","No","Yes","No","No","Yes","No","Yes","Yes","No","No","Yes")
Mstatus=c("Single","Married","Single","Married","Divorced","Married","Divorced","Single","Married","Single","Divorced","Divorced","Married","Married")
income_no=c(60,70,75,100,120,125,200,220,250)
mean(income_no)
sd(income_no)
income_yes=c(50,85,90,150,180)
mean(income_yes)
sd(income_yes)
# P(Hone Owner: Yes, Marital Status: Single, Annual Income: 158)
P_income_no=pnorm(158,135.556,70.42036)
P_income_yes=pnorm(158,111,52.72571)
P_income_yes
P_income_no
table(Default)
addmargins(table(Howner,Default))
addmargins(table(Mstatus,Default))
P_default_yes<-5/14
P_default_no<-9/14
P_how_yes<-1/5
P_how_no<-5/9
p_mst_single_yes<-2/5
p_mst_single_no<-2/9
p_mst_married_yes<-1/5
p_mst_married_no<-5/9
p_mst_divorced_yes<-2/5
p_mst_divorced_no<-2/9
P_h_yes=prod(P_how_yes,p_mst_single_yes,P_income_yes,P_default_yes)
P_h_yes
P_h_no=prod(P_how_no,p_mst_single_no,P_income_no,P_default_no)
P_h_no
max(P_h_no,P_h_yes)
# so in this case we would predict no
library(sm)
d1<-ggplot(Wells, aes(x =arsenic)) +
geom_density() +
facet_wrap(~switch)
d1
d2<-ggplot(Wells, aes(x =distance)) +
geom_density() +
facet_wrap(~switch)
d2
d3<-ggplot(Wells, aes(x =education)) +
geom_density() +
facet_wrap(~switch)
d3
performance(P_Test,"auc")@y.values
library(caret)
library(ROCR)
library(e1071)
Income=c(125,100,70,120,150,60,220,85,75,90,180,200,250,50)
Howner=c("Yes","No","No","Yes","No","No","Yes","No","No","No","Yes","Yes","Yes","No")
Default=c("No","No","No","No","Yes","No","No","Yes","No","Yes","Yes","No","No","Yes")
Mstatus=c("Single","Married","Single","Married","Divorced","Married","Divorced","Single","Married","Single","Divorced","Divorced","Married","Married")
income_no=c(60,70,75,100,120,125,200,220,250)
mean(income_no)
sd(income_no)
income_yes=c(50,85,90,150,180)
mean(income_yes)
sd(income_yes)
# P(Hone Owner: Yes, Marital Status: Single, Annual Income: 158)
P_income_no=pnorm(158,135.556,70.42036)
P_income_yes=pnorm(158,111,52.72571)
P_income_yes
P_income_no
table(Default)
addmargins(table(Howner,Default))
addmargins(table(Mstatus,Default))
P_default_yes<-5/14
P_default_no<-9/14
P_how_yes<-1/5
P_how_no<-5/9
p_mst_single_yes<-2/5
p_mst_single_no<-2/9
p_mst_married_yes<-1/5
p_mst_married_no<-5/9
p_mst_divorced_yes<-2/5
p_mst_divorced_no<-2/9
P_h_yes=prod(P_how_yes,p_mst_single_yes,P_income_yes,P_default_yes)
P_h_yes
P_h_no=prod(P_how_no,p_mst_single_no,P_income_no,P_default_no)
P_h_no
max(P_h_no,P_h_yes)
# so in this case we would predict no
d1<-ggplot(Wells, aes(x =arsenic)) +
geom_density() +
facet_wrap(~switch)
d1
d2<-ggplot(Wells, aes(x =distance)) +
geom_density() +
facet_wrap(~switch)
d2
d3<-ggplot(Wells, aes(x =education)) +
geom_density() +
facet_wrap(~switch)
d3
